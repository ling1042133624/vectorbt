{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "from numba import njit\n",
    "\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt import risk_models\n",
    "from pypfopt import expected_returns\n",
    "from pypfopt import base_optimizer\n",
    "\n",
    "import vectorbt as vbt\n",
    "from vectorbt.generic.nb import nanmean_nb\n",
    "from vectorbt.portfolio.nb import order_nb, sort_call_seq_nb\n",
    "from vectorbt.portfolio.enums import SizeType, Direction"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "# Define params\n",
    "symbols = ['FB', 'AMZN', 'NFLX', 'GOOG', 'AAPL']\n",
    "start_date = datetime(2017, 1, 1, tzinfo=pytz.utc)\n",
    "end_date = datetime(2020, 1, 1, tzinfo=pytz.utc)\n",
    "num_tests = 2000\n",
    "\n",
    "vbt.settings.array_wrapper['freq'] = 'days'\n",
    "vbt.settings.returns['year_freq'] = '252 days'\n",
    "vbt.settings.portfolio['seed'] = 42\n",
    "vbt.settings.portfolio.stats['incl_unrealized'] = True"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "yfdata = vbt.YFData.download(symbols, start=start_date, end=end_date)\n",
    "\n",
    "print(yfdata.symbols)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "ohlcv = yfdata.concat()\n",
    "\n",
    "print(ohlcv.keys())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "price = ohlcv['Close']"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "# Plot normalized price series\n",
    "(price / price.iloc[0]).vbt.plot().show_svg()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "returns = price.pct_change()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "source": [
    "print(returns.mean())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "source": [
    "print(returns.std())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "source": [
    "print(returns.corr())"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vectorbt: Random search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-time allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Generate random weights, n times\n",
    "weights = []\n",
    "for i in range(num_tests):\n",
    "    w = np.random.random_sample(len(symbols))\n",
    "    w = w / np.sum(w)\n",
    "    weights.append(w)\n",
    "\n",
    "print(len(weights))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "source": [
    "# Build column hierarchy such that one weight corresponds to one price series\n",
    "_price = price.vbt.tile(num_tests, keys=pd.Index(np.arange(num_tests), name='symbol_group'))\n",
    "_price = _price.vbt.stack_index(pd.Index(np.concatenate(weights), name='weights'))\n",
    "\n",
    "print(_price.columns)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "source": [
    "# Define order size\n",
    "size = np.full_like(_price, np.nan)\n",
    "size[0, :] = np.concatenate(weights)  # allocate at first timestamp, do nothing afterwards\n",
    "\n",
    "print(size.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "source": [
    "# Run simulation\n",
    "pf = vbt.Portfolio.from_orders(\n",
    "    close=_price,\n",
    "    size=size,\n",
    "    size_type='targetpercent',\n",
    "    group_by='symbol_group',\n",
    "    cash_sharing=True\n",
    ") # all weights sum to 1, no shorting, and 100% investment in risky assets\n",
    "\n",
    "print(len(pf.orders))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "source": [
    "# Plot annualized return against volatility, color by sharpe ratio\n",
    "annualized_return = pf.annualized_return()\n",
    "annualized_return.index = pf.annualized_volatility()\n",
    "annualized_return.vbt.scatterplot(\n",
    "    trace_kwargs=dict(\n",
    "        mode='markers', \n",
    "        marker=dict(\n",
    "            color=pf.sharpe_ratio(),\n",
    "            colorbar=dict(\n",
    "                title='sharpe_ratio'\n",
    "            ),\n",
    "            size=5,\n",
    "            opacity=0.7\n",
    "        )\n",
    "    ),\n",
    "    xaxis_title='annualized_volatility',\n",
    "    yaxis_title='annualized_return'\n",
    ").show_svg()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "source": [
    "# Get index of the best group according to the target metric\n",
    "best_symbol_group = pf.sharpe_ratio().idxmax()\n",
    "\n",
    "print(best_symbol_group)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "source": [
    "# Print best weights\n",
    "print(weights[best_symbol_group])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "source": [
    "# Compute default stats\n",
    "print(pf.iloc[best_symbol_group].stats())"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rebalance monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "source": [
    "# Select the first index of each month\n",
    "rb_mask = ~_price.index.to_period('m').duplicated()\n",
    "\n",
    "print(rb_mask.sum())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "source": [
    "rb_size = np.full_like(_price, np.nan)\n",
    "rb_size[rb_mask, :] = np.concatenate(weights)  # allocate at mask\n",
    "\n",
    "print(rb_size.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "source": [
    "# Run simulation, with rebalancing monthly\n",
    "rb_pf = vbt.Portfolio.from_orders(\n",
    "    close=_price,\n",
    "    size=rb_size,\n",
    "    size_type='targetpercent',\n",
    "    group_by='symbol_group',\n",
    "    cash_sharing=True,\n",
    "    call_seq='auto'  # important: sell before buy\n",
    ")\n",
    "\n",
    "print(len(rb_pf.orders))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "source": [
    "rb_best_symbol_group = rb_pf.sharpe_ratio().idxmax()\n",
    "\n",
    "print(rb_best_symbol_group)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "source": [
    "print(weights[rb_best_symbol_group])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "source": [
    "print(rb_pf.iloc[rb_best_symbol_group].stats())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "source": [
    "def plot_allocation(rb_pf):\n",
    "    # Plot weights development of the portfolio\n",
    "    rb_asset_value = rb_pf.asset_value(group_by=False)\n",
    "    rb_value = rb_pf.value()\n",
    "    rb_idxs = np.flatnonzero((rb_pf.asset_flow() != 0).any(axis=1))\n",
    "    rb_dates = rb_pf.wrapper.index[rb_idxs]\n",
    "    fig = (rb_asset_value.vbt / rb_value).vbt.plot(\n",
    "        trace_names=symbols,\n",
    "        trace_kwargs=dict(\n",
    "            stackgroup='one'\n",
    "        )\n",
    "    )\n",
    "    for rb_date in rb_dates:\n",
    "        fig.add_shape(\n",
    "            dict(\n",
    "                xref='x',\n",
    "                yref='paper',\n",
    "                x0=rb_date,\n",
    "                x1=rb_date,\n",
    "                y0=0,\n",
    "                y1=1,\n",
    "                line_color=fig.layout.template.layout.plot_bgcolor\n",
    "            )\n",
    "        )\n",
    "    fig.show_svg()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "source": [
    "plot_allocation(rb_pf.iloc[rb_best_symbol_group])  # best group"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search and rebalance every 30 days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilize low-level API to dynamically search for best Sharpe ratio and rebalance accordingly. Compared to previous method, we won't utilize stacking, but do search in a loop instead. We also will use days instead of months, as latter may contain a various number of trading days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "source": [
    "srb_sharpe = np.full(price.shape[0], np.nan)\n",
    "\n",
    "@njit\n",
    "def pre_sim_func_nb(c, every_nth):\n",
    "    # Define rebalancing days\n",
    "    c.segment_mask[:, :] = False\n",
    "    c.segment_mask[every_nth::every_nth, :] = True\n",
    "    return ()\n",
    "\n",
    "@njit\n",
    "def find_weights_nb(c, price, num_tests):\n",
    "    # Find optimal weights based on best Sharpe ratio\n",
    "    returns = (price[1:] - price[:-1]) / price[:-1]\n",
    "    returns = returns[1:, :]  # cannot compute np.cov with NaN\n",
    "    mean = nanmean_nb(returns)\n",
    "    cov = np.cov(returns, rowvar=False)  # masked arrays not supported by Numba (yet)\n",
    "    best_sharpe_ratio = -np.inf\n",
    "    weights = np.full(c.group_len, np.nan, dtype=np.float_)\n",
    "    \n",
    "    for i in range(num_tests):\n",
    "        # Generate weights\n",
    "        w = np.random.random_sample(c.group_len)\n",
    "        w = w / np.sum(w)\n",
    "        \n",
    "        # Compute annualized mean, covariance, and Sharpe ratio\n",
    "        p_return = np.sum(mean * w) * ann_factor\n",
    "        p_std = np.sqrt(np.dot(w.T, np.dot(cov, w))) * np.sqrt(ann_factor)\n",
    "        sharpe_ratio = p_return / p_std\n",
    "        if sharpe_ratio > best_sharpe_ratio:\n",
    "            best_sharpe_ratio = sharpe_ratio\n",
    "            weights = w\n",
    "            \n",
    "    return best_sharpe_ratio, weights\n",
    "\n",
    "@njit\n",
    "def pre_segment_func_nb(c, find_weights_nb, history_len, ann_factor, num_tests, srb_sharpe):\n",
    "    if history_len == -1:\n",
    "        # Look back at the entire time period\n",
    "        close = c.close[:c.i, c.from_col:c.to_col]\n",
    "    else:\n",
    "        # Look back at a fixed time period\n",
    "        if c.i - history_len <= 0:\n",
    "            return (np.full(c.group_len, np.nan),)  # insufficient data\n",
    "        close = c.close[c.i - history_len:c.i, c.from_col:c.to_col]\n",
    "\n",
    "    # Find optimal weights\n",
    "    best_sharpe_ratio, weights = find_weights_nb(c, close, num_tests)\n",
    "    srb_sharpe[c.i] = best_sharpe_ratio\n",
    "\n",
    "    # Update valuation price and reorder orders\n",
    "    size_type = SizeType.TargetPercent\n",
    "    direction = Direction.LongOnly\n",
    "    order_value_out = np.empty(c.group_len, dtype=np.float_)\n",
    "    for k in range(c.group_len):\n",
    "        col = c.from_col + k\n",
    "        c.last_val_price[col] = c.close[c.i, col]\n",
    "    sort_call_seq_nb(c, weights, size_type, direction, order_value_out)\n",
    "\n",
    "    return (weights,)\n",
    "\n",
    "@njit\n",
    "def order_func_nb(c, weights):\n",
    "    col_i = c.call_seq_now[c.call_idx]\n",
    "    return order_nb(\n",
    "        weights[col_i], \n",
    "        c.close[c.i, c.col],\n",
    "        size_type=SizeType.TargetPercent\n",
    "    )"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "source": [
    "ann_factor = returns.vbt.returns.ann_factor"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "source": [
    "# Run simulation using a custom order function\n",
    "srb_pf = vbt.Portfolio.from_order_func(\n",
    "    price,\n",
    "    order_func_nb,\n",
    "    pre_sim_func_nb=pre_sim_func_nb,\n",
    "    pre_sim_args=(30,),\n",
    "    pre_segment_func_nb=pre_segment_func_nb,\n",
    "    pre_segment_args=(find_weights_nb, -1, ann_factor, num_tests, srb_sharpe),\n",
    "    cash_sharing=True, \n",
    "    group_by=True\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "source": [
    "# Plot best Sharpe ratio at each rebalancing day\n",
    "pd.Series(srb_sharpe, index=price.index).vbt.scatterplot(trace_kwargs=dict(mode='markers')).show_svg()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "source": [
    "print(srb_pf.stats())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "source": [
    "plot_allocation(srb_pf)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see how weights stabilize themselves with growing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "source": [
    "# Run simulation, but now consider only the last 252 days of data\n",
    "srb252_sharpe = np.full(price.shape[0], np.nan)\n",
    "\n",
    "srb252_pf = vbt.Portfolio.from_order_func(\n",
    "    price,\n",
    "    order_func_nb,\n",
    "    pre_sim_func_nb=pre_sim_func_nb,\n",
    "    pre_sim_args=(30,),\n",
    "    pre_segment_func_nb=pre_segment_func_nb,\n",
    "    pre_segment_args=(find_weights_nb, 252, ann_factor, num_tests, srb252_sharpe),\n",
    "    cash_sharing=True, \n",
    "    group_by=True\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "source": [
    "pd.Series(srb252_sharpe, index=price.index).vbt.scatterplot(trace_kwargs=dict(mode='markers')).show_svg()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "source": [
    "print(srb252_pf.stats())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "source": [
    "plot_allocation(srb252_pf)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A much more volatile weight distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyPortfolioOpt + vectorbt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-time allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "source": [
    "# Calculate expected returns and sample covariance amtrix\n",
    "avg_returns = expected_returns.mean_historical_return(price)\n",
    "cov_mat = risk_models.sample_cov(price)\n",
    "\n",
    "# Get weights maximizing the Sharpe ratio\n",
    "ef = EfficientFrontier(avg_returns, cov_mat)\n",
    "weights = ef.max_sharpe()\n",
    "clean_weights = ef.clean_weights()\n",
    "pyopt_weights = np.array([clean_weights[symbol] for symbol in symbols])\n",
    "\n",
    "print(pyopt_weights)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "source": [
    "pyopt_size = np.full_like(price, np.nan)\n",
    "pyopt_size[0, :] = pyopt_weights  # allocate at first timestamp, do nothing afterwards\n",
    "\n",
    "print(pyopt_size.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "source": [
    "# Run simulation with weights from PyPortfolioOpt\n",
    "pyopt_pf = vbt.Portfolio.from_orders(\n",
    "    close=price,\n",
    "    size=pyopt_size,\n",
    "    size_type='targetpercent',\n",
    "    group_by=True,\n",
    "    cash_sharing=True\n",
    ")\n",
    "\n",
    "print(len(pyopt_pf.orders))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faster than stacking solution, but doesn't let you compare weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "source": [
    "print(pyopt_pf.stats())"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search and rebalance monthly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can't use third-party optimization packages within Numba (yet).\n",
    "\n",
    "Here you have two choices:\n",
    "1) Use `os.environ['NUMBA_DISABLE_JIT'] = '1'` before all imports to disable Numba completely\n",
    "2) Disable Numba for the function, but also for every other function in the stack that calls it\n",
    "\n",
    "We will demonstrate the second option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "source": [
    "def pyopt_find_weights(sc, price, num_tests):  # no @njit decorator = it's a pure Python function\n",
    "    # Calculate expected returns and sample covariance matrix\n",
    "    price = pd.DataFrame(price, columns=symbols)\n",
    "    avg_returns = expected_returns.mean_historical_return(price)\n",
    "    cov_mat = risk_models.sample_cov(price)\n",
    "\n",
    "    # Get weights maximizing the Sharpe ratio\n",
    "    ef = EfficientFrontier(avg_returns, cov_mat)\n",
    "    weights = ef.max_sharpe()\n",
    "    clean_weights = ef.clean_weights()\n",
    "    weights = np.array([clean_weights[symbol] for symbol in symbols])\n",
    "    best_sharpe_ratio = base_optimizer.portfolio_performance(weights, avg_returns, cov_mat)[2]\n",
    "            \n",
    "    return best_sharpe_ratio, weights"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "source": [
    "pyopt_srb_sharpe = np.full(price.shape[0], np.nan)\n",
    "\n",
    "# Run simulation with a custom order function\n",
    "pyopt_srb_pf = vbt.Portfolio.from_order_func(\n",
    "    price,\n",
    "    order_func_nb,\n",
    "    pre_sim_func_nb=pre_sim_func_nb,\n",
    "    pre_sim_args=(30,),\n",
    "    pre_segment_func_nb=pre_segment_func_nb.py_func,  # run pre_segment_func_nb as pure Python function\n",
    "    pre_segment_args=(pyopt_find_weights, -1, ann_factor, num_tests, pyopt_srb_sharpe),\n",
    "    cash_sharing=True, \n",
    "    group_by=True,\n",
    "    use_numba=False  # run simulate_nb as pure Python function\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "source": [
    "pd.Series(pyopt_srb_sharpe, index=price.index).vbt.scatterplot(trace_kwargs=dict(mode='markers')).show_svg()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "source": [
    "print(pyopt_srb_pf.stats())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "source": [
    "plot_allocation(pyopt_srb_pf)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
